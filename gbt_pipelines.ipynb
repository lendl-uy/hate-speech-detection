{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657e43c3",
   "metadata": {},
   "source": [
    "# LDA - GBT Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cef84980d4467",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:13:19.059134Z",
     "start_time": "2024-04-30T06:13:17.609454Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from constants import CLEANED_DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffafa63beef650",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e92953c8b90f034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:13:19.060866Z",
     "start_time": "2024-04-30T06:13:19.055058Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be051016d14124",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the Hate Speech Filipino dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b506f040054ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:13:31.058160Z",
     "start_time": "2024-04-30T06:13:19.142009Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from dataset/cleaned_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(full_data_path=CLEANED_DATASET_PATH,\n",
    "                  from_scratch=False,\n",
    "                  split_sizes=[10000, 4232, 4232])\n",
    "dataset.build()\n",
    "\n",
    "X_train = dataset.get_features(split_type=\"train\")\n",
    "Y_train = dataset.get_labels(split_type=\"train\")\n",
    "X_val = dataset.get_features(split_type=\"val\")\n",
    "Y_val = dataset.get_labels(split_type=\"val\")\n",
    "X_test = dataset.get_features(split_type=\"test\")\n",
    "Y_test = dataset.get_labels(split_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64eeb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:13:31.113177Z",
     "start_time": "2024-04-30T06:13:30.990078Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-split the dataset into training, validation, and test sets\n",
    "# X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "# X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8c684144c6b8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Classifier Only Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a447fade33a0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:13:31.262504Z",
     "start_time": "2024-04-30T06:13:31.036560Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_objective(X_train, Y_train, X_test, Y_test, random_seed):\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 10, 100)\n",
    "\n",
    "        # Create the pipeline within the trial\n",
    "        pipeline = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(max_df=0.95, min_df=2)),\n",
    "            (\"gbt\", GradientBoostingClassifier(n_estimators=n_estimators, \n",
    "                                         learning_rate=learning_rate, \n",
    "                                         max_depth=max_depth, \n",
    "                                         random_state=RANDOM_SEED))\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "\n",
    "        # Evaluate the pipeline\n",
    "        Y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        return accuracy\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd05682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-03 21:21:08,374] A new study created in memory with name: GBT_Pipeline\n",
      "[I 2024-05-03 21:22:41,663] Trial 1 finished with value: 0.7143194706994329 and parameters: {'n_estimators': 516, 'learning_rate': 0.005788813256230545, 'max_depth': 13}. Best is trial 1 with value: 0.7143194706994329.\n",
      "[I 2024-05-03 21:23:36,788] Trial 0 finished with value: 0.7136105860113422 and parameters: {'n_estimators': 559, 'learning_rate': 0.004293169087471002, 'max_depth': 16}. Best is trial 1 with value: 0.7143194706994329.\n",
      "[I 2024-05-03 21:23:40,379] Trial 9 finished with value: 0.7150283553875236 and parameters: {'n_estimators': 251, 'learning_rate': 0.008085571657796728, 'max_depth': 27}. Best is trial 9 with value: 0.7150283553875236.\n",
      "[I 2024-05-03 21:24:12,107] Trial 8 finished with value: 0.7053402646502835 and parameters: {'n_estimators': 332, 'learning_rate': 0.0055385245233496114, 'max_depth': 25}. Best is trial 9 with value: 0.7150283553875236.\n",
      "[I 2024-05-03 21:24:20,936] Trial 2 finished with value: 0.6899810964083176 and parameters: {'n_estimators': 113, 'learning_rate': 0.006034353725446237, 'max_depth': 90}. Best is trial 9 with value: 0.7150283553875236.\n",
      "[I 2024-05-03 21:25:52,588] Trial 11 finished with value: 0.7372400756143668 and parameters: {'n_estimators': 641, 'learning_rate': 0.008602319663749197, 'max_depth': 28}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:25:57,475] Trial 13 finished with value: 0.6977788279773157 and parameters: {'n_estimators': 359, 'learning_rate': 0.003894825846174809, 'max_depth': 19}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:26:15,426] Trial 3 finished with value: 0.7261342155009451 and parameters: {'n_estimators': 388, 'learning_rate': 0.009327293790810858, 'max_depth': 38}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:26:17,752] Trial 12 finished with value: 0.7152646502835539 and parameters: {'n_estimators': 347, 'learning_rate': 0.005914399580572886, 'max_depth': 27}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:26:46,536] Trial 4 finished with value: 0.7308601134215501 and parameters: {'n_estimators': 508, 'learning_rate': 0.007724406881952642, 'max_depth': 34}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:26:53,503] Trial 14 finished with value: 0.724007561436673 and parameters: {'n_estimators': 378, 'learning_rate': 0.00788054055097042, 'max_depth': 25}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:30:35,087] Trial 20 finished with value: 0.6944706994328923 and parameters: {'n_estimators': 554, 'learning_rate': 0.0024440108087216248, 'max_depth': 21}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:31:01,009] Trial 16 finished with value: 0.6843100189035917 and parameters: {'n_estimators': 716, 'learning_rate': 0.001222411900821559, 'max_depth': 24}. Best is trial 11 with value: 0.7372400756143668.\n",
      "[I 2024-05-03 21:31:43,529] Trial 5 finished with value: 0.7384215500945179 and parameters: {'n_estimators': 920, 'learning_rate': 0.009979937594792538, 'max_depth': 50}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:31:49,025] Trial 18 finished with value: 0.7088846880907372 and parameters: {'n_estimators': 899, 'learning_rate': 0.0019260904931901884, 'max_depth': 19}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:32:54,581] Trial 7 finished with value: 0.725897920604915 and parameters: {'n_estimators': 666, 'learning_rate': 0.006384907113970867, 'max_depth': 55}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:33:16,679] Trial 17 finished with value: 0.6937618147448015 and parameters: {'n_estimators': 304, 'learning_rate': 0.0014677798365039, 'max_depth': 62}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:35:15,770] Trial 19 finished with value: 0.7017958412098299 and parameters: {'n_estimators': 323, 'learning_rate': 0.006214842591220711, 'max_depth': 87}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:36:41,963] Trial 15 finished with value: 0.7263705103969754 and parameters: {'n_estimators': 801, 'learning_rate': 0.007345042597377339, 'max_depth': 61}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:38:03,551] Trial 10 finished with value: 0.7079395085066162 and parameters: {'n_estimators': 753, 'learning_rate': 0.002293969909973044, 'max_depth': 61}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:38:26,875] Trial 23 finished with value: 0.7362948960302458 and parameters: {'n_estimators': 826, 'learning_rate': 0.009740592171757413, 'max_depth': 51}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:38:39,930] Trial 6 finished with value: 0.7143194706994329 and parameters: {'n_estimators': 830, 'learning_rate': 0.0057057869867826235, 'max_depth': 83}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:39:14,526] Trial 24 finished with value: 0.7367674858223062 and parameters: {'n_estimators': 999, 'learning_rate': 0.009379986588949155, 'max_depth': 49}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:40:44,750] Trial 22 finished with value: 0.7062854442344045 and parameters: {'n_estimators': 825, 'learning_rate': 0.0018613145877732981, 'max_depth': 52}. Best is trial 5 with value: 0.7384215500945179.\n",
      "[I 2024-05-03 21:42:32,524] Trial 21 finished with value: 0.693289224952741 and parameters: {'n_estimators': 867, 'learning_rate': 0.0007597437893979934, 'max_depth': 63}. Best is trial 5 with value: 0.7384215500945179.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training accuracy: 0.7384215500945179\n",
      "Best training hyperparameters: {'n_estimators': 920, 'learning_rate': 0.009979937594792538, 'max_depth': 50}\n"
     ]
    }
   ],
   "source": [
    "# Create the objective function\n",
    "objective = create_objective(X_train, Y_train, X_val, Y_val, RANDOM_SEED)\n",
    "\n",
    "# Create an Optuna study object\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=f\"GBT_Pipeline\")\n",
    "\n",
    "# Execute an optimization by running trials\n",
    "study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "best_gbt_params = study.best_trial.params\n",
    "\n",
    "# Best trial result\n",
    "print(f\"Best training accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best training hyperparameters: {best_gbt_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28de712f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test accuracy: 0.7384215500945179\n",
      "Best test hyperparameters: {'n_estimators': 920, 'learning_rate': 0.009979937594792538, 'max_depth': 50}\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(max_df=0.95, min_df=2)),\n",
    "    (\"gbt\", GradientBoostingClassifier(n_estimators=best_gbt_params[\"n_estimators\"], \n",
    "                                         learning_rate=best_gbt_params[\"learning_rate\"], \n",
    "                                         max_depth=best_gbt_params[\"max_depth\"], \n",
    "                                         random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Best testing result\n",
    "print(f\"Best test accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best test hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a427da",
   "metadata": {},
   "source": [
    "## NMF-GBT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4d5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective(X_train, Y_train, X_test, Y_test, best_gbt_params, random_seed):\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_topics = trial.suggest_int(\"n_topics\", 50, 300)\n",
    "\n",
    "        # Create the pipeline within the trial\n",
    "        pipeline = Pipeline([\n",
    "            (\"vectorizer\", CountVectorizer(max_df=0.95, min_df=2)),\n",
    "            (\"nmf\", NMF(n_components=n_topics, random_state=random_seed)),\n",
    "            (\"gbt\", GradientBoostingClassifier(n_estimators=best_gbt_params[\"n_estimators\"], \n",
    "                                         learning_rate=best_gbt_params[\"learning_rate\"], \n",
    "                                         max_depth=best_gbt_params[\"max_depth\"], \n",
    "                                         random_state=RANDOM_SEED))\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, Y_train)\n",
    "\n",
    "        # Evaluate the pipeline\n",
    "        Y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        return accuracy\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd87507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-03 21:47:37,371] A new study created in memory with name: NMF_GBT_Pipeline\n",
      "c:\\Users\\lendl\\Documents\\hate-speech-detection\\venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lendl\\Documents\\hate-speech-detection\\venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "[I 2024-05-03 22:02:50,837] Trial 2 finished with value: 0.6580812854442344 and parameters: {'n_topics': 74}. Best is trial 2 with value: 0.6580812854442344.\n",
      "[I 2024-05-03 22:04:03,602] Trial 6 finished with value: 0.650992438563327 and parameters: {'n_topics': 88}. Best is trial 2 with value: 0.6580812854442344.\n",
      "[I 2024-05-03 22:07:53,664] Trial 8 finished with value: 0.6604442344045368 and parameters: {'n_topics': 113}. Best is trial 8 with value: 0.6604442344045368.\n",
      "[I 2024-05-03 22:08:18,680] Trial 9 finished with value: 0.6651701323251418 and parameters: {'n_topics': 106}. Best is trial 9 with value: 0.6651701323251418.\n",
      "c:\\Users\\lendl\\Documents\\hate-speech-detection\\venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "[I 2024-05-03 22:17:54,701] Trial 13 finished with value: 0.6254725897920604 and parameters: {'n_topics': 51}. Best is trial 9 with value: 0.6651701323251418.\n",
      "[I 2024-05-03 22:19:10,587] Trial 10 finished with value: 0.6722589792060492 and parameters: {'n_topics': 151}. Best is trial 10 with value: 0.6722589792060492.\n",
      "[I 2024-05-03 22:22:07,816] Trial 14 finished with value: 0.6387051039697542 and parameters: {'n_topics': 53}. Best is trial 10 with value: 0.6722589792060492.\n",
      "[I 2024-05-03 22:26:08,280] Trial 5 finished with value: 0.6921077504725898 and parameters: {'n_topics': 170}. Best is trial 5 with value: 0.6921077504725898.\n",
      "[I 2024-05-03 22:27:52,820] Trial 11 finished with value: 0.6937618147448015 and parameters: {'n_topics': 189}. Best is trial 11 with value: 0.6937618147448015.\n",
      "[I 2024-05-03 22:30:20,036] Trial 3 finished with value: 0.7013232514177694 and parameters: {'n_topics': 193}. Best is trial 3 with value: 0.7013232514177694.\n",
      "[I 2024-05-03 22:32:08,379] Trial 16 finished with value: 0.6309073724007561 and parameters: {'n_topics': 58}. Best is trial 3 with value: 0.7013232514177694.\n",
      "[I 2024-05-03 22:32:30,878] Trial 7 finished with value: 0.7034499054820416 and parameters: {'n_topics': 206}. Best is trial 7 with value: 0.7034499054820416.\n",
      "[I 2024-05-03 22:33:08,086] Trial 0 finished with value: 0.7053402646502835 and parameters: {'n_topics': 212}. Best is trial 0 with value: 0.7053402646502835.\n",
      "c:\\Users\\lendl\\Documents\\hate-speech-detection\\venv\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1770: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "[I 2024-05-03 22:35:06,058] Trial 17 finished with value: 0.650047258979206 and parameters: {'n_topics': 75}. Best is trial 0 with value: 0.7053402646502835.\n",
      "[I 2024-05-03 22:39:51,841] Trial 20 finished with value: 0.6427221172022685 and parameters: {'n_topics': 52}. Best is trial 0 with value: 0.7053402646502835.\n",
      "[I 2024-05-03 22:40:19,314] Trial 4 finished with value: 0.7079395085066162 and parameters: {'n_topics': 274}. Best is trial 4 with value: 0.7079395085066162.\n",
      "[I 2024-05-03 22:40:59,484] Trial 1 finished with value: 0.7166824196597353 and parameters: {'n_topics': 256}. Best is trial 1 with value: 0.7166824196597353.\n"
     ]
    }
   ],
   "source": [
    "# Create the objective function\n",
    "objective = create_objective(X_train, Y_train, X_val, Y_val, best_gbt_params, RANDOM_SEED)\n",
    "\n",
    "# Create an Optuna study object\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=f\"NMF_GBT_Pipeline\")\n",
    "\n",
    "# Execute an optimization by running trials\n",
    "study.optimize(objective, n_trials=25, n_jobs=-1)\n",
    "\n",
    "best_nmf_params = study.best_trial.params\n",
    "\n",
    "# Best trial result\n",
    "print(f\"Best training accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best training hyperparameters: {best_nmf_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit the pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(max_df=0.95, min_df=2)),\n",
    "    (\"nmf\", NMF(n_components=best_nmf_params[\"n_topics\"], \n",
    "                random_state=RANDOM_SEED)),\n",
    "    (\"rf\", GradientBoostingClassifier(n_estimators=best_gbt_params[\"n_estimators\"], \n",
    "                                         learning_rate=best_gbt_params[\"learning_rate\"], \n",
    "                                         max_depth=best_gbt_params[\"max_depth\"], \n",
    "                                         random_state=RANDOM_SEED))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Best testing result\n",
    "print(f\"Best test accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best test hyperparameters: {study.best_trial.params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
