{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from bitermplus import BTM\n",
    "from dataset.dataset import Dataset\n",
    "from constants import CLEANED_DATASET_PATH\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from constants import CLEANED_DATASET_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from dataset/cleaned_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(full_data_path=CLEANED_DATASET_PATH,\n",
    "                  from_scratch=False,\n",
    "                  split_sizes=[10000, 4232, 4232])\n",
    "dataset.build()\n",
    "\n",
    "X_train = dataset.get_features(split_type=\"train\")\n",
    "Y_train = dataset.get_labels(split_type=\"train\")\n",
    "X_val = dataset.get_features(split_type=\"val\")\n",
    "Y_val = dataset.get_labels(split_type=\"val\")\n",
    "X_test = dataset.get_features(split_type=\"test\")\n",
    "Y_test = dataset.get_labels(split_type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 4232\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2277\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa  # Importing the pyarrow library\n",
    "\n",
    "# Create individual datasets\n",
    "train_dataset = pd.DataFrame({\"text\": X_train, \"label\": Y_train})\n",
    "val_dataset = pd.DataFrame({\"text\": X_val, \"label\": Y_val})\n",
    "test_dataset = pd.DataFrame({\"text\": X_test, \"label\": Y_test})\n",
    "\n",
    "# Convert pandas DataFrame to pyarrow.Table\n",
    "train_arrow_table = pa.Table.from_pandas(train_dataset)\n",
    "val_arrow_table = pa.Table.from_pandas(val_dataset)\n",
    "test_arrow_table = pa.Table.from_pandas(test_dataset)\n",
    "\n",
    "# Create DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": Dataset(train_arrow_table),\n",
    "    \"val\": Dataset(val_arrow_table),\n",
    "    \"test\": Dataset(test_arrow_table),\n",
    "})\n",
    "\n",
    "# Print the DatasetDict\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb80227bb5af4819b753d6ba29894cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d4ce6a78834081b0b825a59b9a1197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d3f57d66fb4d3999918ee977f68fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with optimizations\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,  # Increased batch size\n",
    "    per_device_eval_batch_size=32,  # Increased batch size\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_num_workers=4,  # More workers for data loading\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=500,  # Log less frequently\n",
    "    save_total_limit=2,  # Limit the total number of checkpoints\n",
    "    report_to=\"none\"  # Disable reporting to speed up\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tokenized_imdb[\"train\"]\n",
    "te = tokenized_imdb[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142aed27295543fab7daecdb823c0622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bd2316d6be44d7a8bfaa0ec0c8ff29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6012217998504639, 'eval_runtime': 130.0842, 'eval_samples_per_second': 17.504, 'eval_steps_per_second': 0.553, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322b005c0943469397297634283ba9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5595399737358093, 'eval_runtime': 125.8358, 'eval_samples_per_second': 18.095, 'eval_steps_per_second': 0.572, 'epoch': 1.99}\n",
      "{'train_runtime': 3249.2925, 'train_samples_per_second': 6.155, 'train_steps_per_second': 0.096, 'train_loss': 0.6074763077955979, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=312, training_loss=0.6074763077955979, metrics={'train_runtime': 3249.2925, 'train_samples_per_second': 6.155, 'train_steps_per_second': 0.096, 'total_flos': 315799044195840.0, 'train_loss': 0.6074763077955979, 'epoch': 1.9936102236421727})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tr,\n",
    "    eval_dataset=te,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20339d1a55d64e4e8872b5523e31504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5595399737358093, 'eval_runtime': 124.6342, 'eval_samples_per_second': 18.269, 'eval_steps_per_second': 0.578, 'epoch': 1.9936102236421727}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8670482039451599}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text = \"goodness jejomar binay super annoying mo pls stop like really oo laki hirap punyeta\"\n",
    "classifier = pipeline(\"text-classification\", model=\"C:/Users/vince/Documents/Python/hate-speech-detection/my_awesome_model/checkpoint-312\")\n",
    "classifier(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        label     score\n",
      "0     LABEL_0  0.730444\n",
      "1     LABEL_1  0.839643\n",
      "2     LABEL_0  0.944241\n",
      "3     LABEL_0  0.909857\n",
      "4     LABEL_0  0.760844\n",
      "...       ...       ...\n",
      "4227  LABEL_1  0.842102\n",
      "4228  LABEL_1  0.775408\n",
      "4229  LABEL_1  0.725372\n",
      "4230  LABEL_1  0.857052\n",
      "4231  LABEL_0  0.704660\n",
      "\n",
      "[4232 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define your text classification pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"C:/Users/vince/Documents/Python/hate-speech-detection/my_awesome_model/checkpoint-312\")\n",
    "\n",
    "# Use list comprehension to classify texts\n",
    "results = [classifier(text)[0] for text in X_val]\n",
    "\n",
    "# Create DataFrame directly from the results\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print or use the DataFrame as needed\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.applymap(lambda x: ''.join(filter(str.isdigit,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = y_pred['label']\n",
    "# Convert y_pred to integers\n",
    "y_pred_int = y_pred_list.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.719281663516068\n",
      "Precision: 0.6799343455067706\n",
      "Recall: 0.8024213075060532\n",
      "F1 Score: 0.7361172812083517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(Y_val, y_pred_int)\n",
    "precision = precision_score(Y_val, y_pred_int, average='binary')\n",
    "recall = recall_score(Y_val, y_pred_int, average='binary')\n",
    "f1 = f1_score(Y_val, y_pred_int, average='binary')\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
