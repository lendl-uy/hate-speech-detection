{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c48592",
   "metadata": {},
   "source": [
    "# LDA - XGBoost Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cef84980d4467",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:34.266840Z",
     "start_time": "2024-04-30T06:15:34.253920Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffafa63beef650",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e92953c8b90f034",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:35.143992Z",
     "start_time": "2024-04-30T06:15:35.093759Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be051016d14124",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the Hate Speech Filipino dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b506f040054ff5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.281786Z",
     "start_time": "2024-04-30T06:15:35.782572Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"hate_speech_filipino\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d8361405fe5257",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.323889Z",
     "start_time": "2024-04-30T06:15:47.281457Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]\n",
    "test_set = dataset[\"test\"]\n",
    "\n",
    "X_train, Y_train = train_set[\"text\"], train_set[\"label\"]\n",
    "X_val, Y_val = validation_set[\"text\"], validation_set[\"label\"]\n",
    "X_test, Y_test = test_set[\"text\"], test_set[\"label\"]\n",
    "\n",
    "X = X_train + X_val + X_test\n",
    "Y = Y_train + Y_val + Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e592255b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.339678Z",
     "start_time": "2024-04-30T06:15:47.320434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8c684144c6b8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Vectorize the texts to be able to perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a447fade33a0d8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.453074Z",
     "start_time": "2024-04-30T06:15:47.392457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "X_train_vector = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7d5a4",
   "metadata": {},
   "source": [
    "## Perform Latent Dirichlet Allocation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ae0e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Latent Dirichlet Allocation for 10 topics\n",
      "Done performing Latent Dirichlet Allocation for 10 topics\n"
     ]
    }
   ],
   "source": [
    "N_TOPICS = 10\n",
    "print(f\"Performing Latent Dirichlet Allocation for {N_TOPICS} topics\")\n",
    "lda = LatentDirichletAllocation(n_components=N_TOPICS, random_state=RANDOM_SEED)\n",
    "X_train_topics = lda.fit_transform(X_train_vector)\n",
    "print(f\"Done performing Latent Dirichlet Allocation for {N_TOPICS} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a8f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform validation and test data using the fitted vectorizer and LDA\n",
    "X_val_counts = vectorizer.transform(X_val)\n",
    "X_val_topics = lda.transform(X_val_counts)\n",
    "\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_topics = lda.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67aa981",
   "metadata": {},
   "source": [
    "## Train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56546fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def create_objective(X_train, Y_train, X_test, Y_test):\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "\n",
    "        # Create an XGBoost classifier model with suggested parameters\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            n_estimators=n_estimators,    # Number of trees\n",
    "            learning_rate=learning_rate,  # Learning rate\n",
    "            max_depth=max_depth,          # Depth of the trees\n",
    "            subsample=subsample,          # Subsampling of the training instances\n",
    "            colsample_bytree=colsample_bytree,  # Subsampling of columns for each tree\n",
    "            seed=RANDOM_SEED,             # Seed for reproducibility\n",
    "            use_label_encoder=False,      # Disable label encoder warning\n",
    "            eval_metric=\"logloss\"\n",
    "        )\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        # Predict the labels on the test set\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        return accuracy\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2efd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 00:41:10,538] A new study created in memory with name: LDA_XGBoost_Pipeline\n",
      "[I 2024-04-30 00:41:22,004] Trial 10 finished with value: 0.6562113082955014 and parameters: {'n_estimators': 704, 'learning_rate': 0.006805516016174171, 'max_depth': 3, 'subsample': 0.7258352694258039, 'colsample_bytree': 0.8524639746322628}. Best is trial 10 with value: 0.6562113082955014.\n",
      "[I 2024-04-30 00:41:27,208] Trial 9 finished with value: 0.7853900123813454 and parameters: {'n_estimators': 166, 'learning_rate': 0.0079551214784902, 'max_depth': 19, 'subsample': 0.556533643662955, 'colsample_bytree': 0.7337060732092171}. Best is trial 9 with value: 0.7853900123813454.\n",
      "[I 2024-04-30 00:41:33,829] Trial 8 finished with value: 0.682624845233182 and parameters: {'n_estimators': 585, 'learning_rate': 0.0010407333777397137, 'max_depth': 8, 'subsample': 0.7834933018393802, 'colsample_bytree': 0.5051089578872159}. Best is trial 9 with value: 0.7853900123813454.\n",
      "[I 2024-04-30 00:41:33,989] Trial 1 finished with value: 0.7040858439950475 and parameters: {'n_estimators': 586, 'learning_rate': 0.005763263109057701, 'max_depth': 8, 'subsample': 0.8546177008691209, 'colsample_bytree': 0.7647502945459459}. Best is trial 9 with value: 0.7853900123813454.\n",
      "[I 2024-04-30 00:41:34,436] Trial 11 finished with value: 0.7858027238959967 and parameters: {'n_estimators': 262, 'learning_rate': 0.003329890965045323, 'max_depth': 17, 'subsample': 0.7643214979737898, 'colsample_bytree': 0.5204104844570374}. Best is trial 11 with value: 0.7858027238959967.\n",
      "[I 2024-04-30 00:41:36,080] Trial 0 finished with value: 0.7845645893520429 and parameters: {'n_estimators': 385, 'learning_rate': 0.009812816126000068, 'max_depth': 13, 'subsample': 0.6734053503867565, 'colsample_bytree': 0.7216729384237235}. Best is trial 11 with value: 0.7858027238959967.\n",
      "[I 2024-04-30 00:41:37,944] Trial 15 finished with value: 0.6174164259182832 and parameters: {'n_estimators': 260, 'learning_rate': 0.0016060725369073858, 'max_depth': 3, 'subsample': 0.7280803461224494, 'colsample_bytree': 0.9359134842268519}. Best is trial 11 with value: 0.7858027238959967.\n",
      "[I 2024-04-30 00:41:40,035] Trial 14 finished with value: 0.6198926950061907 and parameters: {'n_estimators': 320, 'learning_rate': 0.0011100180631347374, 'max_depth': 4, 'subsample': 0.8214025637356761, 'colsample_bytree': 0.560481588790532}. Best is trial 11 with value: 0.7858027238959967.\n",
      "[I 2024-04-30 00:41:43,570] Trial 7 finished with value: 0.8171687990094924 and parameters: {'n_estimators': 324, 'learning_rate': 0.006829500848446725, 'max_depth': 19, 'subsample': 0.8869207493866603, 'colsample_bytree': 0.9068279490142039}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:45,753] Trial 18 finished with value: 0.6838629797771357 and parameters: {'n_estimators': 189, 'learning_rate': 0.0032613285847777783, 'max_depth': 9, 'subsample': 0.6393712878889548, 'colsample_bytree': 0.6686749545859927}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:48,891] Trial 17 finished with value: 0.7540239372678498 and parameters: {'n_estimators': 155, 'learning_rate': 0.003254006377447416, 'max_depth': 17, 'subsample': 0.646452699653285, 'colsample_bytree': 0.888151600340315}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:49,419] Trial 13 finished with value: 0.7395790342550557 and parameters: {'n_estimators': 516, 'learning_rate': 0.006975905054867213, 'max_depth': 10, 'subsample': 0.5484271214667975, 'colsample_bytree': 0.7890217643057145}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:51,093] Trial 3 finished with value: 0.8089145687164672 and parameters: {'n_estimators': 672, 'learning_rate': 0.008761940163852771, 'max_depth': 13, 'subsample': 0.8325508878878576, 'colsample_bytree': 0.5066437963141542}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:52,759] Trial 2 finished with value: 0.7779612051176228 and parameters: {'n_estimators': 472, 'learning_rate': 0.0016373623591508335, 'max_depth': 19, 'subsample': 0.6083050794795679, 'colsample_bytree': 0.5123229663060201}. Best is trial 7 with value: 0.8171687990094924.\n",
      "[I 2024-04-30 00:41:54,475] Trial 5 finished with value: 0.8312009905076352 and parameters: {'n_estimators': 502, 'learning_rate': 0.007951984560972385, 'max_depth': 20, 'subsample': 0.7491971504240673, 'colsample_bytree': 0.5616276076732628}. Best is trial 5 with value: 0.8312009905076352.\n",
      "[I 2024-04-30 00:41:54,587] Trial 12 finished with value: 0.786215435410648 and parameters: {'n_estimators': 409, 'learning_rate': 0.004547128695160918, 'max_depth': 19, 'subsample': 0.5539575876840062, 'colsample_bytree': 0.8372607896705131}. Best is trial 5 with value: 0.8312009905076352.\n",
      "[I 2024-04-30 00:41:55,556] Trial 6 finished with value: 0.8080891456871647 and parameters: {'n_estimators': 735, 'learning_rate': 0.008454490860885577, 'max_depth': 15, 'subsample': 0.5052920715227152, 'colsample_bytree': 0.9020839508080711}. Best is trial 5 with value: 0.8312009905076352.\n",
      "[I 2024-04-30 00:41:56,017] Trial 4 finished with value: 0.8076764341725134 and parameters: {'n_estimators': 726, 'learning_rate': 0.00645974137641521, 'max_depth': 16, 'subsample': 0.5961236157089749, 'colsample_bytree': 0.8864527112386522}. Best is trial 5 with value: 0.8312009905076352.\n",
      "[I 2024-04-30 00:41:56,896] Trial 19 finished with value: 0.7073875361122576 and parameters: {'n_estimators': 840, 'learning_rate': 0.0024691049017084915, 'max_depth': 9, 'subsample': 0.67795353325167, 'colsample_bytree': 0.9563619109094699}. Best is trial 5 with value: 0.8312009905076352.\n",
      "[I 2024-04-30 00:41:58,563] Trial 16 finished with value: 0.82294676021461 and parameters: {'n_estimators': 570, 'learning_rate': 0.006844781197744016, 'max_depth': 18, 'subsample': 0.8373150333232106, 'colsample_bytree': 0.8684593238362031}. Best is trial 5 with value: 0.8312009905076352.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8312009905076352\n",
      "Best hyperparameters: {'n_estimators': 502, 'learning_rate': 0.007951984560972385, 'max_depth': 20, 'subsample': 0.7491971504240673, 'colsample_bytree': 0.5616276076732628}\n"
     ]
    }
   ],
   "source": [
    "# Create a study object\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=f\"LDA_XGBoost_Pipeline\")\n",
    "\n",
    "# Create the study objective\n",
    "objective = create_objective(X_train_topics, Y_train, X_val_topics, Y_val)\n",
    "\n",
    "# Execute an optimization\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "\n",
    "# Print the best trial results\n",
    "print(f\"Best Accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42ac769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LDA-XGBoost Model Accuracy: 0.8424092409240924\n"
     ]
    }
   ],
   "source": [
    "best_n_estimators = study.best_trial.params[\"n_estimators\"]\n",
    "best_learning_rate = study.best_trial.params[\"learning_rate\"]\n",
    "best_max_depth = study.best_trial.params[\"max_depth\"]\n",
    "best_subsample = study.best_trial.params[\"subsample\"]\n",
    "best_colsample_bytree = study.best_trial.params[\"colsample_bytree\"]\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=best_n_estimators, \n",
    "                                 learning_rate=best_learning_rate,\n",
    "                                 max_depth=best_max_depth,\n",
    "                                 random_state=RANDOM_SEED)\n",
    "model.fit(X_train_topics, Y_train)\n",
    "Y_pred = model.predict(X_test_topics)\n",
    "score = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Best LDA-XGBoost Model Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# \n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "# X_train_vector = tfidf_vectorizer.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:06:21.973510Z",
     "start_time": "2024-04-30T06:06:21.886286Z"
    }
   },
   "id": "aba09df6f8f5d10c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Non-negative Matrix Factorization for 10 topics\n",
      "Done performing Non-negative Matrix Factorization for 10 topics\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "N_TOPICS = 10\n",
    "print(f\"Performing Non-negative Matrix Factorization for {N_TOPICS} topics\")\n",
    "nmf = NMF(n_components=N_TOPICS, random_state=RANDOM_SEED)\n",
    "X_train_topics = nmf.fit_transform(X_train_vector)\n",
    "print(f\"Done performing Non-negative Matrix Factorization for {N_TOPICS} topics\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:48.120100Z",
     "start_time": "2024-04-30T06:15:47.454853Z"
    }
   },
   "id": "ce10956de3c128c3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Transform validation and test data using the fitted vectorizer and LDA\n",
    "X_val_counts = vectorizer.transform(X_val)\n",
    "X_val_topics = nmf.transform(X_val_counts)\n",
    "\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_topics = nmf.transform(X_test_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:48.278081Z",
     "start_time": "2024-04-30T06:15:48.125640Z"
    }
   },
   "id": "7c776c8fbd170680"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LDA-XGBoost Model Accuracy: 0.8432343234323433\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=502, \n",
    "                         learning_rate=0.007951984560972385,\n",
    "                         max_depth=20,\n",
    "                         subsample=0.7491971504240673,\n",
    "                         colsample_bytree=0.5616276076732628, \n",
    "                         random_state=RANDOM_SEED)\n",
    "model.fit(X_train_topics, Y_train)\n",
    "Y_pred = model.predict(X_test_topics)\n",
    "score = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Best NMF-XGBoost Model Accuracy: {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:52.943679Z",
     "start_time": "2024-04-30T06:15:48.290349Z"
    }
   },
   "id": "ecf56941d16102e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cffc3d883d0abf67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
