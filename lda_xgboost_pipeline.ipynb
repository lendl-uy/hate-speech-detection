{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c48592",
   "metadata": {},
   "source": [
    "# LDA - XGBoost Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778cef84980d4467",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:34.266840Z",
     "start_time": "2024-04-30T06:15:34.253920Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import optuna\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from constants import CLEANED_DATASET_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffafa63beef650",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e92953c8b90f034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:35.143992Z",
     "start_time": "2024-04-30T06:15:35.093759Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be051016d14124",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load the Hate Speech Filipino dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b506f040054ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.281786Z",
     "start_time": "2024-04-30T06:15:35.782572Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from dataset/cleaned_dataset.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "X, Y = dataset.load_from_file(CLEANED_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e592255b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.339678Z",
     "start_time": "2024-04-30T06:15:47.320434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Re-split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8c684144c6b8a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Vectorize the texts to be able to perform LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a447fade33a0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:47.453074Z",
     "start_time": "2024-04-30T06:15:47.392457Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "X_train_vector = vectorizer.fit_transform(X_train)\n",
    "X_val_counts = vectorizer.transform(X_val)\n",
    "X_test_counts = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7d5a4",
   "metadata": {},
   "source": [
    "## Perform Latent Dirichlet Allocation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3ae0e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Latent Dirichlet Allocation for 10 topics\n",
      "Done performing Latent Dirichlet Allocation for 10 topics\n"
     ]
    }
   ],
   "source": [
    "N_TOPICS = 10\n",
    "print(f\"Performing Latent Dirichlet Allocation for {N_TOPICS} topics\")\n",
    "lda = LatentDirichletAllocation(n_components=N_TOPICS, random_state=RANDOM_SEED)\n",
    "X_train_topics = lda.fit_transform(X_train_vector)\n",
    "X_val_topics = lda.transform(X_val_counts)\n",
    "X_test_topics = lda.transform(X_test_counts)\n",
    "print(f\"Done performing Latent Dirichlet Allocation for {N_TOPICS} topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67aa981",
   "metadata": {},
   "source": [
    "## Train the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56546fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def create_objective(X_train, Y_train, X_test, Y_test):\n",
    "    def objective(trial):\n",
    "        # Suggest values for the hyperparameters\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "\n",
    "        # Create an XGBoost classifier model with suggested parameters\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            n_estimators=n_estimators,    # Number of trees\n",
    "            learning_rate=learning_rate,  # Learning rate\n",
    "            max_depth=max_depth,          # Depth of the trees\n",
    "            subsample=subsample,          # Subsampling of the training instances\n",
    "            colsample_bytree=colsample_bytree,  # Subsampling of columns for each tree\n",
    "            seed=RANDOM_SEED,             # Seed for reproducibility\n",
    "            use_label_encoder=False,      # Disable label encoder warning\n",
    "            eval_metric=\"logloss\")\n",
    "\n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        # Predict the labels on the test set\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        return accuracy\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2efd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-30 21:53:53,258] A new study created in memory with name: LDA_XGBoost_Pipeline\n",
      "[I 2024-04-30 21:53:56,124] Trial 4 finished with value: 0.542795232936078 and parameters: {'n_estimators': 177, 'learning_rate': 0.0001119531423060802, 'max_depth': 4, 'subsample': 0.7917199963026285, 'colsample_bytree': 0.8706233085019464}. Best is trial 4 with value: 0.542795232936078.\n",
      "[I 2024-04-30 21:54:00,771] Trial 2 finished with value: 0.6543878656554712 and parameters: {'n_estimators': 548, 'learning_rate': 0.0021934294499675916, 'max_depth': 3, 'subsample': 0.573158936976219, 'colsample_bytree': 0.9157125483339761}. Best is trial 2 with value: 0.6543878656554712.\n",
      "[I 2024-04-30 21:54:04,785] Trial 10 finished with value: 0.6570964247020585 and parameters: {'n_estimators': 470, 'learning_rate': 0.005220537945988417, 'max_depth': 6, 'subsample': 0.886734954010784, 'colsample_bytree': 0.6420609476334334}. Best is trial 10 with value: 0.6570964247020585.\n",
      "[I 2024-04-30 21:54:05,630] Trial 5 finished with value: 0.6554712892741061 and parameters: {'n_estimators': 191, 'learning_rate': 0.007096606687316172, 'max_depth': 15, 'subsample': 0.73144321915531, 'colsample_bytree': 0.9279116045579463}. Best is trial 10 with value: 0.6570964247020585.\n",
      "[I 2024-04-30 21:54:06,161] Trial 1 finished with value: 0.6538461538461539 and parameters: {'n_estimators': 160, 'learning_rate': 0.007466538151751289, 'max_depth': 19, 'subsample': 0.6514836256329927, 'colsample_bytree': 0.7248797277754145}. Best is trial 10 with value: 0.6570964247020585.\n",
      "[I 2024-04-30 21:54:09,445] Trial 15 finished with value: 0.6635969664138678 and parameters: {'n_estimators': 136, 'learning_rate': 0.005569563144917665, 'max_depth': 9, 'subsample': 0.6808846894449416, 'colsample_bytree': 0.6001537535292955}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:11,538] Trial 3 finished with value: 0.6543878656554712 and parameters: {'n_estimators': 661, 'learning_rate': 0.007683009609864847, 'max_depth': 8, 'subsample': 0.99114203485716, 'colsample_bytree': 0.8437899640084532}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:11,679] Trial 11 finished with value: 0.6533044420368364 and parameters: {'n_estimators': 511, 'learning_rate': 0.009274928648915458, 'max_depth': 10, 'subsample': 0.7789722328400983, 'colsample_bytree': 0.8144927661256733}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:12,096] Trial 14 finished with value: 0.6598049837486457 and parameters: {'n_estimators': 399, 'learning_rate': 0.006125480173304354, 'max_depth': 6, 'subsample': 0.7792438363272822, 'colsample_bytree': 0.7734351816545879}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:12,334] Trial 9 finished with value: 0.6560130010834236 and parameters: {'n_estimators': 359, 'learning_rate': 0.006517091069200541, 'max_depth': 14, 'subsample': 0.7826020621846705, 'colsample_bytree': 0.8699959560953796}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:17,792] Trial 17 finished with value: 0.6549295774647887 and parameters: {'n_estimators': 627, 'learning_rate': 0.009396813042734478, 'max_depth': 5, 'subsample': 0.6493766374260274, 'colsample_bytree': 0.735676822635748}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:18,884] Trial 6 finished with value: 0.6484290357529794 and parameters: {'n_estimators': 644, 'learning_rate': 0.008534991125004806, 'max_depth': 12, 'subsample': 0.7728718998681334, 'colsample_bytree': 0.9025322317714319}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:19,002] Trial 13 finished with value: 0.661430119176598 and parameters: {'n_estimators': 702, 'learning_rate': 0.0009907212927484476, 'max_depth': 9, 'subsample': 0.6597844527009487, 'colsample_bytree': 0.778453173272321}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:19,682] Trial 18 finished with value: 0.6592632719393283 and parameters: {'n_estimators': 405, 'learning_rate': 0.006441159296997216, 'max_depth': 8, 'subsample': 0.9352960134854333, 'colsample_bytree': 0.6811171857900775}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:19,726] Trial 8 finished with value: 0.6511375947995667 and parameters: {'n_estimators': 767, 'learning_rate': 0.007079469253288006, 'max_depth': 11, 'subsample': 0.7251279392574312, 'colsample_bytree': 0.8906528399636399}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:26,677] Trial 0 finished with value: 0.6554712892741061 and parameters: {'n_estimators': 755, 'learning_rate': 0.0037704040323905488, 'max_depth': 17, 'subsample': 0.542597414231885, 'colsample_bytree': 0.679524255314303}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:27,537] Trial 7 finished with value: 0.6554712892741061 and parameters: {'n_estimators': 735, 'learning_rate': 0.004792430842052768, 'max_depth': 17, 'subsample': 0.9800255850640867, 'colsample_bytree': 0.7305565078203159}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:27,890] Trial 12 finished with value: 0.647887323943662 and parameters: {'n_estimators': 797, 'learning_rate': 0.009009288641005742, 'max_depth': 17, 'subsample': 0.5654821950964823, 'colsample_bytree': 0.578959142317585}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:28,675] Trial 19 finished with value: 0.6549295774647887 and parameters: {'n_estimators': 463, 'learning_rate': 0.001259495772889822, 'max_depth': 19, 'subsample': 0.6529257478911286, 'colsample_bytree': 0.8236684753238774}. Best is trial 15 with value: 0.6635969664138678.\n",
      "[I 2024-04-30 21:54:29,431] Trial 16 finished with value: 0.6473456121343445 and parameters: {'n_estimators': 902, 'learning_rate': 0.008982793203065035, 'max_depth': 16, 'subsample': 0.5904924492182657, 'colsample_bytree': 0.563133868372814}. Best is trial 15 with value: 0.6635969664138678.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.6635969664138678\n",
      "Best hyperparameters: {'n_estimators': 136, 'learning_rate': 0.005569563144917665, 'max_depth': 9, 'subsample': 0.6808846894449416, 'colsample_bytree': 0.6001537535292955}\n"
     ]
    }
   ],
   "source": [
    "# Create a study object\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=f\"LDA_XGBoost_Pipeline\")\n",
    "\n",
    "# Create the study objective\n",
    "objective = create_objective(X_train_topics, Y_train, X_val_topics, Y_val)\n",
    "\n",
    "# Execute an optimization\n",
    "study.optimize(objective, n_trials=20, n_jobs=-1)\n",
    "\n",
    "# Print the best trial results\n",
    "print(f\"Best Accuracy: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42ac769e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LDA-XGBoost Model Accuracy: 0.6599891716296697\n"
     ]
    }
   ],
   "source": [
    "best_n_estimators = study.best_trial.params[\"n_estimators\"]\n",
    "best_learning_rate = study.best_trial.params[\"learning_rate\"]\n",
    "best_max_depth = study.best_trial.params[\"max_depth\"]\n",
    "best_subsample = study.best_trial.params[\"subsample\"]\n",
    "best_colsample_bytree = study.best_trial.params[\"colsample_bytree\"]\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=best_n_estimators, \n",
    "                                 learning_rate=best_learning_rate,\n",
    "                                 max_depth=best_max_depth,\n",
    "                                 random_state=RANDOM_SEED)\n",
    "model.fit(X_train_topics, Y_train)\n",
    "Y_pred = model.predict(X_test_topics)\n",
    "score = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Best LDA-XGBoost Model Accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aba09df6f8f5d10c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:06:21.973510Z",
     "start_time": "2024-04-30T06:06:21.886286Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# \n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "# X_train_vector = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce10956de3c128c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:48.120100Z",
     "start_time": "2024-04-30T06:15:47.454853Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Non-negative Matrix Factorization for 20 topics\n",
      "Done performing Non-negative Matrix Factorization for 20 topics\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "N_TOPICS = 20\n",
    "print(f\"Performing Non-negative Matrix Factorization for {N_TOPICS} topics\")\n",
    "nmf = NMF(n_components=N_TOPICS, random_state=RANDOM_SEED)\n",
    "X_train_topics = nmf.fit_transform(X_train_vector)\n",
    "X_val_topics = nmf.transform(X_val_counts)\n",
    "X_test_topics = nmf.transform(X_test_counts)\n",
    "print(f\"Done performing Non-negative Matrix Factorization for {N_TOPICS} topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf56941d16102e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T06:15:52.943679Z",
     "start_time": "2024-04-30T06:15:48.290349Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NMF-XGBoost Model Accuracy: 0.6800216567406605\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=best_n_estimators, \n",
    "                          learning_rate=best_learning_rate,\n",
    "                          max_depth=best_max_depth,\n",
    "                          subsample=best_subsample,\n",
    "                          colsample_bytree=best_colsample_bytree, \n",
    "                          random_state=RANDOM_SEED)\n",
    "model.fit(X_train_topics, Y_train)\n",
    "Y_pred = model.predict(X_test_topics)\n",
    "score = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Best NMF-XGBoost Model Accuracy: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
